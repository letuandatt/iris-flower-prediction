{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b01bc29dc9ee12f",
   "metadata": {},
   "source": [
    "# TẢI BỘ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:34:52.029220Z",
     "start_time": "2024-12-18T13:34:52.018925Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1c0daf6ba0d4963",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:34:52.111738Z",
     "start_time": "2024-12-18T13:34:52.038805Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = './data'\n",
    "train_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e105e56af300d49",
   "metadata": {},
   "source": [
    "# TIỀN XỬ LÝ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39f67bd06287e76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:34:52.270860Z",
     "start_time": "2024-12-18T13:34:52.122807Z"
    }
   },
   "outputs": [],
   "source": [
    "#   Split training: Validation = 0.9 : 0.1\n",
    "VALID_RAIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RAIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, [n_train_examples, n_valid_examples])\n",
    "\n",
    "# Compute mean and std for normalization\n",
    "mean = train_data.dataset.data.float().mean() / 255\n",
    "std = train_data.dataset.data.float().std() / 255\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "train_data.dataset.transform = train_transforms\n",
    "valid_data.dataset.transform = test_transforms\n",
    "\n",
    "#   Create dataloader\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataloader = data.DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c256ad995b922d",
   "metadata": {},
   "source": [
    "# Mô hình LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8643ec3dcee661e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:34:52.288870Z",
     "start_time": "2024-12-18T13:34:52.280403Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNetClassifier, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Adjust input size\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Output: [batch_size, 6, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Output: [batch_size, 16, 5, 5]\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.flatten(x)                  # Output: [batch_size, 16*5*5]\n",
    "        x = F.relu(self.fc1(x))              # Output: [batch_size, 120]\n",
    "        x = F.relu(self.fc2(x))              # Output: [batch_size, 84]\n",
    "        x = self.fc3(x)                      # Output: [batch_size, num_classes]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86dc4d6cd3e651b",
   "metadata": {},
   "source": [
    "# HUẤN LUYỆN MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83ed8cd28254fc12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:34:52.309970Z",
     "start_time": "2024-12-18T13:34:52.300692Z"
    }
   },
   "outputs": [],
   "source": [
    "#   Training function\n",
    "def train(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(\n",
    "                \"| Epoch {:3d} | {:5d}/{:5d} batches | \"\n",
    "                \"| Accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, criterion, device, valid_dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678483be6ed09f4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5214ba4d712cc9b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:37:23.271851Z",
     "start_time": "2024-12-18T13:34:52.320512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   1 |    50/  211 batches | | Accuracy    0.653\n",
      "| Epoch   1 |   100/  211 batches | | Accuracy    0.902\n",
      "| Epoch   1 |   150/  211 batches | | Accuracy    0.929\n",
      "| Epoch   1 |   200/  211 batches | | Accuracy    0.943\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   1 | Time: 13.98s | Train Accuracy    0.952 | Train Loss    0.479 | | Valid Accuracy    0.960 | Valid Loss    0.136 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   2 |    50/  211 batches | | Accuracy    0.961\n",
      "| Epoch   2 |   100/  211 batches | | Accuracy    0.966\n",
      "| Epoch   2 |   150/  211 batches | | Accuracy    0.969\n",
      "| Epoch   2 |   200/  211 batches | | Accuracy    0.973\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   2 | Time: 14.37s | Train Accuracy    0.970 | Train Loss    0.105 | | Valid Accuracy    0.970 | Valid Loss    0.091 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   3 |    50/  211 batches | | Accuracy    0.978\n",
      "| Epoch   3 |   100/  211 batches | | Accuracy    0.976\n",
      "| Epoch   3 |   150/  211 batches | | Accuracy    0.978\n",
      "| Epoch   3 |   200/  211 batches | | Accuracy    0.977\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   3 | Time: 14.19s | Train Accuracy    0.980 | Train Loss    0.072 | | Valid Accuracy    0.983 | Valid Loss    0.055 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   4 |    50/  211 batches | | Accuracy    0.981\n",
      "| Epoch   4 |   100/  211 batches | | Accuracy    0.981\n",
      "| Epoch   4 |   150/  211 batches | | Accuracy    0.982\n",
      "| Epoch   4 |   200/  211 batches | | Accuracy    0.985\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   4 | Time: 14.27s | Train Accuracy    0.982 | Train Loss    0.056 | | Valid Accuracy    0.987 | Valid Loss    0.045 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   5 |    50/  211 batches | | Accuracy    0.986\n",
      "| Epoch   5 |   100/  211 batches | | Accuracy    0.986\n",
      "| Epoch   5 |   150/  211 batches | | Accuracy    0.987\n",
      "| Epoch   5 |   200/  211 batches | | Accuracy    0.987\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   5 | Time: 14.57s | Train Accuracy    0.984 | Train Loss    0.044 | | Valid Accuracy    0.988 | Valid Loss    0.044 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   6 |    50/  211 batches | | Accuracy    0.988\n",
      "| Epoch   6 |   100/  211 batches | | Accuracy    0.989\n",
      "| Epoch   6 |   150/  211 batches | | Accuracy    0.987\n",
      "| Epoch   6 |   200/  211 batches | | Accuracy    0.989\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   6 | Time: 17.82s | Train Accuracy    0.985 | Train Loss    0.037 | | Valid Accuracy    0.984 | Valid Loss    0.048 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   7 |    50/  211 batches | | Accuracy    0.987\n",
      "| Epoch   7 |   100/  211 batches | | Accuracy    0.989\n",
      "| Epoch   7 |   150/  211 batches | | Accuracy    0.988\n",
      "| Epoch   7 |   200/  211 batches | | Accuracy    0.989\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   7 | Time: 17.91s | Train Accuracy    0.993 | Train Loss    0.036 | | Valid Accuracy    0.986 | Valid Loss    0.045 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   8 |    50/  211 batches | | Accuracy    0.990\n",
      "| Epoch   8 |   100/  211 batches | | Accuracy    0.990\n",
      "| Epoch   8 |   150/  211 batches | | Accuracy    0.988\n",
      "| Epoch   8 |   200/  211 batches | | Accuracy    0.990\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   8 | Time: 15.68s | Train Accuracy    0.989 | Train Loss    0.036 | | Valid Accuracy    0.986 | Valid Loss    0.045 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch   9 |    50/  211 batches | | Accuracy    0.991\n",
      "| Epoch   9 |   100/  211 batches | | Accuracy    0.988\n",
      "| Epoch   9 |   150/  211 batches | | Accuracy    0.988\n",
      "| Epoch   9 |   200/  211 batches | | Accuracy    0.989\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   9 | Time: 13.95s | Train Accuracy    0.988 | Train Loss    0.036 | | Valid Accuracy    0.986 | Valid Loss    0.050 |\n",
      "-----------------------------------------------------------\n",
      "| Epoch  10 |    50/  211 batches | | Accuracy    0.990\n",
      "| Epoch  10 |   100/  211 batches | | Accuracy    0.988\n",
      "| Epoch  10 |   150/  211 batches | | Accuracy    0.988\n",
      "| Epoch  10 |   200/  211 batches | | Accuracy    0.990\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  10 | Time: 13.95s | Train Accuracy    0.991 | Train Loss    0.036 | | Valid Accuracy    0.987 | Valid Loss    0.043 |\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_data.dataset.classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lenet = LeNetClassifier(num_classes=num_classes)\n",
    "lenet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet.parameters())\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = './model'\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "eval_accs, eval_losses = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    # Training\n",
    "    train_acc, train_loss = train(\n",
    "        lenet, optimizer, criterion, train_dataloader, device, epoch\n",
    "    )\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluation\n",
    "    eval_acc, eval_loss = evaluate(lenet, criterion, device, valid_dataloader)\n",
    "    eval_accs.append(eval_acc)\n",
    "    eval_losses.append(eval_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if eval_loss < best_loss_eval:\n",
    "        best_loss_eval = eval_loss\n",
    "        torch.save(lenet.state_dict(), save_model + '/lenet_model.pt')\n",
    "\n",
    "    # Print loss, acc and epoch\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} | \"\n",
    "        \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} |\".format(\n",
    "            epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "    # Load best model\n",
    "    lenet.load_state_dict(torch.load(save_model + '/lenet_model.pt'))\n",
    "    lenet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2bc6cffeba295d",
   "metadata": {},
   "source": [
    "# ĐÁNH GIÁ TRÊN TẬP TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "576d172f7604ad2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:37:53.204841Z",
     "start_time": "2024-12-18T13:37:53.140443Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m test_data\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m test_transforms\n\u001b[0;32m      2\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m      3\u001b[0m     test_data,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m test_acc, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlenet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m test_acc, test_loss\n",
      "Cell \u001b[1;32mIn[38], line 48\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, criterion, device, valid_dataloader)\u001b[0m\n\u001b[0;32m     45\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(valid_dataloader):\n\u001b[0;32m     49\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     50\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:316\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    170\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:191\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "test_acc, test_loss = evaluate(lenet, criterion, device, test_dataloader)\n",
    "test_acc, test_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
